{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of mask_rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cabroderick/ML-AM-MQP/blob/main/mask_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4VO3uF19i5B"
      },
      "source": [
        "**Testing Mask-RCNN on sample dataset provided from ME team**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7bd8Qd1sqK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c7c7dc-3163-42f4-ed54-8bb57e955a42"
      },
      "source": [
        "# uninstall improper package versions\n",
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Keras 2.0.8\n",
            "Uninstalling Keras-2.0.8:\n",
            "  Successfully uninstalled Keras-2.0.8\n",
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: Keras-Preprocessing 1.1.2\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\n",
            "Found existing installation: tensorflow 1.13.1\n",
            "Uninstalling tensorflow-1.13.1:\n",
            "  Successfully uninstalled tensorflow-1.13.1\n",
            "Found existing installation: h5py 2.10.0\n",
            "Uninstalling h5py-2.10.0:\n",
            "  Successfully uninstalled h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-gPN3riwtmAS",
        "outputId": "76f37b30-ba61-446d-cb5e-c3c669a0726a"
      },
      "source": [
        "# reinstall with proper versions\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install keras==2.0.8\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "  Using cached tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.41.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.5.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.8.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.6.0)\n",
            "Installing collected packages: h5py, keras-preprocessing, tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-3.5.0 keras-preprocessing-1.1.2 tensorflow-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "keras_preprocessing",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.0.8\n",
            "  Using cached Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.19.5)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.0.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.5.0\n",
            "    Uninstalling h5py-3.5.0:\n",
            "      Successfully uninstalled h5py-3.5.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6y9RJx8fFSD",
        "outputId": "3ef23dfa-ffe4-4b1e-ec85-0139db1a9708"
      },
      "source": [
        "# import mask rcnn and set up\n",
        "%cd\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "%cd Mask_RCNN/\n",
        "!python setup.py install\n",
        "!pip show mask-rcnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n",
            "/root/Mask_RCNN\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n",
            "Name: mask-rcnn\n",
            "Version: 2.1\n",
            "Summary: Mask R-CNN for object detection and instance segmentation\n",
            "Home-page: https://github.com/matterport/Mask_RCNN\n",
            "Author: Matterport\n",
            "Author-email: waleed.abdulla@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMYTaei-TXMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9f4430-e412-4419-982f-c0dd01cc556a"
      },
      "source": [
        "# import training data\n",
        "%cd\n",
        "!git clone https://github.com/cabroderick/ML-AM-MQP\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Cloning into 'ML-AM-MQP'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 159 (delta 18), reused 87 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (159/159), 132.36 MiB | 20.04 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Checking out files: 100% (109/109), done.\n",
            "Mask_RCNN  ML-AM-MQP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKtu9Ah7DCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f70456d-8cb4-407e-dc03-0da8c79382b1"
      },
      "source": [
        "# list data contents\n",
        "%cd '~/ML-AM-MQP/Data/Trial/H6'\n",
        "!ls\n",
        "%cd '~/ML-AM-MQP/Data/Trial/Labeled H6'\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/ML-AM-MQP/Data/Trial/H6\n",
            "A1H6COL_10X_BF_ZUYL_11.tif     A1H6COL_10X_BF_ZUYL_22.tif\n",
            "A1H6COL_10X_BF_ZUYL_12.tif     A1H6COL_10X_BF_ZUYL_23.tif\n",
            "A1H6COL_10X_BF_ZUYL_13.tif     A1H6COL_10X_BF_ZUYL_24.tif\n",
            "A1H6COL_10X_BF_ZUYL_14.tif     A1H6COL_10X_BF_ZUYL_25.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.1.tif  A1H6COL_10X_BF_ZUYL_26.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.2.tif  A1H6COL_10X_BF_ZUYL_27.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.3.tif  A1H6COL_10X_BF_ZUYL_28.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.4.tif  A1H6COL_10X_BF_ZUYL_291.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.5.tif  A1H6COL_10X_BF_ZUYL_29.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.6.tif  A1H6COL_10X_BF_ZUYL_31.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.7.tif  A1H6COL_10X_BF_ZUYL_32.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.8.tif  A1H6COL_10X_BF_ZUYL_33.tif\n",
            "A1H6COL_10X_BF_ZUYL_1.5.9.tif  A1H6COL_10X_BF_ZUYL_34.tif\n",
            "A1H6COL_10X_BF_ZUYL_15.tif     A1H6COL_10X_BF_ZUYL_35.tif\n",
            "A1H6COL_10X_BF_ZUYL_16.tif     A1H6COL_10X_BF_ZUYL_36.tif\n",
            "A1H6COL_10X_BF_ZUYL_17.tif     A1H6COL_10X_BF_ZUYL_37.tif\n",
            "A1H6COL_10X_BF_ZUYL_18.tif     A1H6COL_10X_BF_ZUYL_38.tif\n",
            "A1H6COL_10X_BF_ZUYL_19.tif     A1H6COL_10X_BF_ZUYL_39.tif\n",
            "A1H6COL_10X_BF_ZUYL_21.tif\n",
            "/root/ML-AM-MQP/Data/Trial/Labeled H6\n",
            "A1H6COL_10X_BF_ZUYL_11_labeled.json\tA1H6COL_10X_BF_ZUYL_21_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_12_labeled.json\tA1H6COL_10X_BF_ZUYL_22_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_13_labeled.json\tA1H6COL_10X_BF_ZUYL_23_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_14_labeled.json\tA1H6COL_10X_BF_ZUYL_24_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.1.json\t\tA1H6COL_10X_BF_ZUYL_25_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.1_labeled.json\tA1H6COL_10X_BF_ZUYL_26.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.2_labeled.json\tA1H6COL_10X_BF_ZUYL_26_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.3_labeled.json\tA1H6COL_10X_BF_ZUYL_27_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.4_labeled.json\tA1H6COL_10X_BF_ZUYL_28_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.5_labeled.json\tA1H6COL_10X_BF_ZUYL_291_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.6_labeled.json\tA1H6COL_10X_BF_ZUYL_29_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.7_labeled.json\tA1H6COL_10X_BF_ZUYL_31_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.8_labeled.json\tA1H6COL_10X_BF_ZUYL_32_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_1.5.9_labeled.json\tA1H6COL_10X_BF_ZUYL_33_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_15_labeled.json\tA1H6COL_10X_BF_ZUYL_34_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_16_labeled.json\tA1H6COL_10X_BF_ZUYL_35_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_17_labeled.json\tA1H6COL_10X_BF_ZUYL_36_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_18_labeled.json\tA1H6COL_10X_BF_ZUYL_37_labeled.json\n",
            "A1H6COL_10X_BF_ZUYL_19_labeled.json\tA1H6COL_10X_BF_ZUYL_38_labeled.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5NBHWwrrXCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f81c284-21cb-4fd3-dd08-4c79552808c6"
      },
      "source": [
        "# imports\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "from cv2 import imread\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import urllib.request"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRBaSTI-SUM",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354b313e-c737-4338-c3f1-abc35d701f9f"
      },
      "source": [
        "# configure network\n",
        "\n",
        "class CustomConfig(Config):\n",
        "    NAME = \"object\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 2\n",
        "    # number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 2\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    LEARNING_RATE = .001\n",
        "\n",
        "config = CustomConfig()\n",
        "\n",
        "# set up dataset\n",
        "\n",
        "class AMDataset(utils.Dataset):\n",
        "  def load_dataset(self, validation=False):\n",
        "    IMAGES_DIR = \"/root/ML-AM-MQP/Data/Trial/H6/\"\n",
        "    ANNOTATIONS_DIR = '/root/ML-AM-MQP/Data/Trial/Labeled H6/'\n",
        "    IMG_WIDTH = 1280\n",
        "    IMG_HEIGHT = 1024\n",
        "\n",
        "    self.add_class('dataset', 1, 'gas porosity')\n",
        "    self.add_class('dataset', 2, 'lack of fusion porosity')\n",
        "\n",
        "    val_images = 5 # keeps track of images to reserve for validation set\n",
        "    total_images = len(os.listdir(IMAGES_DIR))\n",
        "    for filename in os.listdir(IMAGES_DIR):\n",
        "      if validation and val_images > 0:\n",
        "        val_images -=1\n",
        "        continue\n",
        "      if (not validation) and val_images < total_images:\n",
        "        val_images += 1\n",
        "        continue\n",
        "\n",
        "      image_id = filename[:-4]\n",
        "      image_path = IMAGES_DIR + image_id + '.tif'\n",
        "      annotation_path = ANNOTATIONS_DIR + image_id + '_labeled.json'\n",
        "      self.add_image('dataset',\n",
        "                     image_id=image_id, \n",
        "                     path=image_path, \n",
        "                     annotation=annotation_path,\n",
        "                     width=IMG_WIDTH,\n",
        "                     height=IMG_HEIGHT)\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    class_ids = list() # list of class ids corresponding to each mask in the mask list\n",
        "    image_info = self.image_info[image_id] # extract image info from data added earlier\n",
        "\n",
        "    width = image_info['width']\n",
        "    height = image_info['height']\n",
        "    path = image_info['annotation']\n",
        "\n",
        "    masks_index = 0 # keep track of index for use in masks\n",
        "\n",
        "    boxes = self.extract_boxes(path) # extract mask data from json file\n",
        "    masks = np.zeros([height, width, len(boxes)], dtype='uint8') # initialize array of masks for each bounding box\n",
        "    for i in range(len(boxes)):\n",
        "      box = boxes[i]\n",
        "      for key in box:\n",
        "        if (box[key]): # make sure box is not empty\n",
        "          col_s, col_e = int(box[key][0][0]), int(box[key][0][1])\n",
        "          row_s, row_e = int(box[key][1][0]), int(box[key][1][1])\n",
        "          masks[row_s:row_e, col_s:col_e, masks_index] = 1\n",
        "          masks_index += 1\n",
        "          class_ids.append(self.class_names.index(key))\n",
        "\n",
        "    return masks, np.array(class_ids)\n",
        "\n",
        "  def extract_boxes(self, filename): # helper to extract bounding boxes from json\n",
        "      f = open(filename,)\n",
        "      data = json.load(f)\n",
        "\n",
        "      boxes = [] # store box coordinates in a dictionary corresponding to labels\n",
        "\n",
        "      for i in data['shapes']:\n",
        "        if i['shape_type'] == 'rectangle':\n",
        "          box = {'gas porosity': [], 'lack of fusion porosity': []}\n",
        "          label = i['label']\n",
        "          box[label] = i['points']\n",
        "          boxes.append(box)\n",
        " \n",
        "      return boxes\n",
        "\n",
        "# set up train and validation data\n",
        "\n",
        "dataset_train = AMDataset()\n",
        "dataset_train.load_dataset(validation=False)\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = AMDataset()\n",
        "dataset_val.load_dataset(validation=True)\n",
        "dataset_val.prepare()\n",
        "\n",
        "# configure model and load coco weights\n",
        "\n",
        "urllib.request.urlretrieve(\"https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5\", \"mask_rcnn_coco.h5\")\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=CustomConfig())\n",
        "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "# train model\n",
        "model.train(train_dataset=dataset_train,\n",
        "            val_dataset=dataset_val,\n",
        "            learning_rate=.001,\n",
        "            epochs=1,\n",
        "            layers='heads')\n",
        "\n",
        "# save training results to external file\n",
        "model_path = 'custom_maskrcnn_weights.h5'\n",
        "model.save_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: ./object20211108T1847/mask_rcnn_object_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n",
            "  1/100 [..............................] - ETA: 20272s - loss: 9.0617 - rpn_class_loss: 0.0582 - rpn_bbox_loss: 1.6319 - mrcnn_class_loss: 1.7714 - mrcnn_bbox_loss: 0.7898 - mrcnn_mask_loss: 4.8104"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIg90Xo3qY8C"
      },
      "source": [
        "\n",
        "# example of inference with a pre-trained coco model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        " \n",
        "# draw an image with detected objects\n",
        "def draw_image_with_boxes(filename, boxes_list):\n",
        "     # load the image\n",
        "     data = pyplot.imread(filename)\n",
        "     # plot the image\n",
        "     pyplot.imshow(data)\n",
        "     # get the context for drawing boxes\n",
        "     ax = pyplot.gca()\n",
        "     # plot each box\n",
        "     for box in boxes_list:\n",
        "          # get coordinates\n",
        "          y1, x1, y2, x2 = box\n",
        "          # calculate width and height of the box\n",
        "          width, height = x2 - x1, y2 - y1\n",
        "          # create the shape\n",
        "          rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "          # draw the box\n",
        "          ax.add_patch(rect)\n",
        "     # show the plot\n",
        "     pyplot.show()\n",
        " \n",
        "# define the test configuration\n",
        "class TestConfig(Config):\n",
        "     NAME = \"test\"\n",
        "     GPU_COUNT = 1\n",
        "     IMAGES_PER_GPU = 1\n",
        "     NUM_CLASSES = 1 + 80\n",
        " \n",
        "# define the model\n",
        "rcnn = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n",
        "# load coco model weights\n",
        "rcnn.load_weights('mask_rcnn_coco.h5', by_name=True)\n",
        "# load photograph\n",
        "img = load_img('img.tif')\n",
        "img = img_to_array(img)\n",
        "# make prediction\n",
        "results = rcnn.detect([img], verbose=0)\n",
        "# visualize the results\n",
        "draw_image_with_boxes('img.tif', results[0]['rois'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}